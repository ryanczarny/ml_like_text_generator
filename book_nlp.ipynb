{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085b9ad6-6166-41ce-bdac-fcf912a00815",
   "metadata": {},
   "source": [
    "https://www.loc.gov/free-to-use/classic-childrens-books/\n",
    "\n",
    "https://concretecomputing.com/thoughts/list-of-public-domain-free-books-for-kids-by-grade-level/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f66bb3-d453-4dc8-848c-55fa49de3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebooklib import epub\n",
    "import os\n",
    "import ebooklib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37bf4e0-1954-45e3-ab3c-bd2fc6eea254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_list = [\"<class 'ebooklib.epub.EpubImage'>\",\"<class 'ebooklib.epub.EpubItem'>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f10c7a-f6e6-4faa-8992-3566ed2bdb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books = []\n",
    "for filename in os.listdir('books/'):\n",
    "    if filename.endswith('.epub'):\n",
    "        book = epub.read_epub('books/' + filename)\n",
    "        book_text = ''\n",
    "        for doc in book.get_items():\n",
    "            if not str(type(doc)) in ignore_list:\n",
    "                doc_content = doc.content.decode()\n",
    "                book_text += doc_content\n",
    "        book_text = book_text.split('\\n')\n",
    "        for line in book_text:\n",
    "            if line.startswith('<p>'):\n",
    "                line = line.replace('<p>','').replace('</p>','')\n",
    "                line=line.replace(';','.').replace('!','.').replace('?','.')\n",
    "                line = line.split(\".\")\n",
    "                for sent in line:\n",
    "                    if sent.startswith(\" \"):\n",
    "                        sent = sent[1:]\n",
    "                    if sent.endswith(\" \"):\n",
    "                        sent = sent[:-1]\n",
    "                    if '<a' in sent:\n",
    "                        sent_start = sent.split('<a')[0]\n",
    "                        try:\n",
    "                            sent_end = sent.split('</a>')[1]\n",
    "                        except:\n",
    "                            sent_end = ''\n",
    "                        sent = sent_start + sent_end\n",
    "                    # html = 0\n",
    "                    # while html == 0:\n",
    "                    #     try:\n",
    "                    #         sent_start = sent.split('<a')[0]\n",
    "                    #         sent_end = sent.split('</a>')[1]\n",
    "                    #         sent = sent_start + sent_end\n",
    "                    #     except:\n",
    "                    #         html = 1\n",
    "                    \n",
    "                    sent = sent.replace('<i>','').replace('</i>','').replace('<b>','').replace('</b>','')\n",
    "                    if len(sent) > 1 and sent != '<br/>':\n",
    "                        all_books.append(sent.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede64be2-f0d6-42ec-8ad3-221787428a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}\n",
    "reverse_corpus = {0:''}\n",
    "counter=1\n",
    "punct = ['!','\"','#','$','%','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[','\\\\',']','^','_','`','{','Â¦','}','~']\n",
    "for sent in all_books:\n",
    "    for punc in punct:\n",
    "        sent=sent.replace(punc,' ')\n",
    "    sent=sent.split(' ')\n",
    "    for word in sent:\n",
    "        if not word in corpus and word != ' ' and len(word) > 0:\n",
    "            corpus[word]=counter\n",
    "            reverse_corpus[counter]=word\n",
    "            counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc82912-20e5-4181-bf11-fc192e9a3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books_indexed = []\n",
    "for sent in all_books:\n",
    "    temp_list = []\n",
    "    for punc in punct:\n",
    "        sent=sent.replace(punc,' ')\n",
    "    sent=sent.split(' ')\n",
    "    for word in sent:\n",
    "        try:\n",
    "            temp_list.append(corpus[word])\n",
    "        except:\n",
    "            continue\n",
    "    all_books_indexed.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff33eab2-6de9-4d3d-bd59-f135fb4e4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "for i in all_books_indexed:\n",
    "    if len(i) > max_length:\n",
    "        max_length = len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d142d1f-192a-44f6-9965-69904bd3bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "for i in range(len(all_books_indexed)):\n",
    "    if len(all_books_indexed[i]) > max_length:\n",
    "        max_length = len(all_books_indexed[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd66bab-9c0d-429f-8411-9f487667b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_books_indexed)):\n",
    "    while len(all_books_indexed[i]) < max_length:\n",
    "        all_books_indexed[i].insert(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a26e7e3-81b8-42cc-8394-d89126ef9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict = {}\n",
    "for sent in all_books_indexed:\n",
    "    for i in range(max_length):\n",
    "        if not i in position_dict:\n",
    "            position_dict[i] = [{}]\n",
    "        if not sent[i] in position_dict[i][0]:\n",
    "            position_dict[i][0][sent[i]]=1\n",
    "        else:\n",
    "            position_dict[i][0][sent[i]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3017fbf7-bc7e-428c-98f6-f2ab25771aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for position in position_dict:\n",
    "    total = 0\n",
    "    temp_list = []\n",
    "    temp_word_list = []\n",
    "    for word in position_dict[position][0]:\n",
    "        count = position_dict[position][0][word]\n",
    "        temp_list.append(count)\n",
    "        temp_word_list.append(word)\n",
    "        total += count\n",
    "    for i in range(len(temp_list)):\n",
    "        temp_list[i] = temp_list[i]/total\n",
    "        if i >= 1:\n",
    "            temp_list[i] += temp_list[i-1]\n",
    "    position_dict[position].append(temp_list)\n",
    "    position_dict[position].append(temp_word_list)\n",
    "total_sents = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0a3a4b2-45e3-47d7-8a0f-687a99347c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full_sentence = []\n",
    "# for i in range(max_length):\n",
    "#     rand_num = random.random()\n",
    "\n",
    "#     position_weights = position_dict[i][1]\n",
    "\n",
    "#     indexer = 0\n",
    "#     for x in range(len(position_weights)):\n",
    "#         if rand_num > position_weights[x]:\n",
    "#             indexer = x\n",
    "\n",
    "#     full_sentence.append(reverse_corpus[position_dict[i][2][indexer]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7a792-4153-4052-b56f-cba51b34cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict_2 = {}\n",
    "for sent in all_books_indexed:\n",
    "    for i in range(max_length):\n",
    "        if not i in position_dict_2:\n",
    "            position_dict_2[i] = [{}]\n",
    "        if i > 0:\n",
    "            if not (sent[i-1],sent[i]) in position_dict_2[i][0]:\n",
    "                position_dict_2[i][0][(sent[i-1],sent[i])]=1\n",
    "            else:\n",
    "                position_dict_2[i][0][(sent[i-1],sent[i])]+=1\n",
    "        else:\n",
    "            if not (0,0) in position_dict_2[i][0]:\n",
    "                position_dict_2[i][0][(0,0)]=1\n",
    "            else:\n",
    "                position_dict_2[i][0][(0,0)]+=1\n",
    "\n",
    "for position in position_dict_2:\n",
    "    total = 0\n",
    "    temp_list = []\n",
    "    temp_word_list = []\n",
    "    for word in position_dict_2[position][0]:\n",
    "        count = position_dict_2[position][0][word]\n",
    "        temp_list.append(count)\n",
    "        temp_word_list.append(word)\n",
    "        total += count\n",
    "    for i in range(len(temp_list)):\n",
    "        temp_list[i] = temp_list[i]/total\n",
    "        if i >= 1:\n",
    "            temp_list[i] += temp_list[i-1]\n",
    "    position_dict_2[position].append(temp_list)\n",
    "    position_dict_2[position].append(temp_word_list)\n",
    "total_sents = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8db7cbd-60e1-40c4-8a59-ea8cdc037507",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict_3 = {}\n",
    "for sent in all_books_indexed:\n",
    "    for i in range(max_length):\n",
    "        if not i in position_dict_3:\n",
    "            position_dict_3[i] = [{}]\n",
    "        if i > 1:\n",
    "            if not (sent[i-2],sent[i-1],sent[i]) in position_dict_3[i][0]:\n",
    "                position_dict_3[i][0][(sent[i-2],sent[i-1],sent[i])]=1\n",
    "            else:\n",
    "                position_dict_3[i][0][(sent[i-2],sent[i-1],sent[i])]+=1\n",
    "        else:\n",
    "            if not (0,0,0) in position_dict_3[i][0]:\n",
    "                position_dict_3[i][0][(0,0,0)]=1\n",
    "            else:\n",
    "                position_dict_3[i][0][(0,0,0)]+=1\n",
    "\n",
    "for position in position_dict_3:\n",
    "    total = 0\n",
    "    temp_list = []\n",
    "    temp_word_list = []\n",
    "    for word in position_dict_3[position][0]:\n",
    "        count = position_dict_3[position][0][word]\n",
    "        temp_list.append(count)\n",
    "        temp_word_list.append(word)\n",
    "        total += count\n",
    "    for i in range(len(temp_list)):\n",
    "        temp_list[i] = temp_list[i]/total\n",
    "        if i >= 1:\n",
    "            temp_list[i] += temp_list[i-1]\n",
    "    position_dict_3[position].append(temp_list)\n",
    "    position_dict_3[position].append(temp_word_list)\n",
    "total_sents = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ee310dc-031d-45ac-8dc7-720059739185",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict_4 = {}\n",
    "for sent in all_books_indexed:\n",
    "    for i in range(max_length):\n",
    "        if not i in position_dict_4:\n",
    "            position_dict_4[i] = [{}]\n",
    "        if i > 2:\n",
    "            if not (sent[i-3],sent[i-2],sent[i-1],sent[i]) in position_dict_4[i][0]:\n",
    "                position_dict_4[i][0][(sent[i-3],sent[i-2],sent[i-1],sent[i])]=1\n",
    "            else:\n",
    "                position_dict_4[i][0][(sent[i-3],sent[i-2],sent[i-1],sent[i])]+=1\n",
    "        else:\n",
    "            if not (0,0,0,0) in position_dict_4[i][0]:\n",
    "                position_dict_4[i][0][(0,0,0,0)]=1\n",
    "            else:\n",
    "                position_dict_4[i][0][(0,0,0,0)]+=1\n",
    "\n",
    "for position in position_dict_4:\n",
    "    total = 0\n",
    "    temp_list = []\n",
    "    temp_word_list = []\n",
    "    for word in position_dict_4[position][0]:\n",
    "        count = position_dict_4[position][0][word]\n",
    "        temp_list.append(count)\n",
    "        temp_word_list.append(word)\n",
    "        total += count\n",
    "    for i in range(len(temp_list)):\n",
    "        temp_list[i] = temp_list[i]/total\n",
    "        if i >= 1:\n",
    "            temp_list[i] += temp_list[i-1]\n",
    "    position_dict_4[position].append(temp_list)\n",
    "    position_dict_4[position].append(temp_word_list)\n",
    "total_sents = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4124218-f712-4c00-9ea3-1e74b838a821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_sent = ''\n",
    "full_sent_len = 0\n",
    "random_base = 0\n",
    "while full_sent_len < 1:\n",
    "    full_sentence = []\n",
    "    for i in range(max_length):\n",
    "        rand_num = random.uniform(random_base,1)\n",
    "        if i == 0:\n",
    "            position_weights = position_dict[i][1]\n",
    "\n",
    "            indexer = 0\n",
    "            for x in range(len(position_weights)):\n",
    "                if rand_num > position_weights[x]:\n",
    "                    indexer = x\n",
    "\n",
    "            full_sentence.append(reverse_corpus[position_dict[i][2][indexer]])\n",
    "            full_sent+=reverse_corpus[position_dict[i][2][indexer]]\n",
    "        # else:\n",
    "        elif i ==1:\n",
    "            temp_list = []\n",
    "            word_list = []\n",
    "            total_count = 0\n",
    "            position_words = position_dict_2[i][2]\n",
    "            for pos in position_words:\n",
    "                pos0 = reverse_corpus[int(pos[0])]\n",
    "                if full_sentence[i-1] == pos0 :\n",
    "                    total_count += position_dict_2[i][0][pos]\n",
    "                    word_list.append(pos)\n",
    "            for pos in word_list:\n",
    "                temp_val= position_dict_2[i][0][pos]\n",
    "                temp_list.append(temp_val/total_count)\n",
    "            for val in range(len(temp_list)):\n",
    "                if val > 0:\n",
    "                    temp_list[val] += temp_list[val-1]\n",
    "            indexer = 0\n",
    "            for x in range(len(temp_list)):\n",
    "                if rand_num > temp_list[x]:\n",
    "                        indexer = x\n",
    "            full_sentence.append(reverse_corpus[word_list[indexer][1]])\n",
    "            full_sent+=reverse_corpus[word_list[indexer][1]]\n",
    "        elif i ==2:\n",
    "            temp_list = []\n",
    "            word_list = []\n",
    "            total_count = 0\n",
    "            position_words = position_dict_3[i][2]\n",
    "            for pos in position_words:\n",
    "                pos0 = reverse_corpus[int(pos[0])]\n",
    "                pos1 = reverse_corpus[int(pos[1])]\n",
    "                if full_sentence[i-1] == pos1 and full_sentence[i-2] == pos0:\n",
    "                    total_count += position_dict_3[i][0][pos]\n",
    "                    word_list.append(pos)\n",
    "            for pos in word_list:\n",
    "                temp_val= position_dict_3[i][0][pos]\n",
    "                temp_list.append(temp_val/total_count)\n",
    "            for val in range(len(temp_list)):\n",
    "                if val > 0:\n",
    "                    temp_list[val] += temp_list[val-1]\n",
    "            indexer = 0\n",
    "            for x in range(len(temp_list)):\n",
    "                if rand_num > temp_list[x]:\n",
    "                        indexer = x\n",
    "            full_sentence.append(reverse_corpus[word_list[indexer][2]])\n",
    "            full_sent+=reverse_corpus[word_list[indexer][2]]\n",
    "        else:\n",
    "        # elif i ==1:\n",
    "            temp_list = []\n",
    "            word_list = []\n",
    "            total_count = 0\n",
    "            position_words = position_dict_4[i][2]\n",
    "            for pos in position_words:\n",
    "                pos0 = reverse_corpus[int(pos[0])]\n",
    "                pos1 = reverse_corpus[int(pos[1])]\n",
    "                pos2 = reverse_corpus[int(pos[2])]\n",
    "                if full_sentence[i-1] == pos2 and full_sentence[i-2] == pos1 and full_sentence[i-3] == pos0:\n",
    "                    total_count += position_dict_4[i][0][pos]\n",
    "                    word_list.append(pos)\n",
    "            for pos in word_list:\n",
    "                temp_val= position_dict_4[i][0][pos]\n",
    "                temp_list.append(temp_val/total_count)\n",
    "            for val in range(len(temp_list)):\n",
    "                if val > 0:\n",
    "                    temp_list[val] += temp_list[val-1]\n",
    "            indexer = 0\n",
    "            for x in range(len(temp_list)):\n",
    "                if rand_num > temp_list[x]:\n",
    "                        indexer = x\n",
    "            full_sentence.append(reverse_corpus[word_list[indexer][3]])\n",
    "            full_sent+=reverse_corpus[word_list[indexer][3]]\n",
    "        \n",
    "    full_sent_len = len(full_sent)\n",
    "    random_base += 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e153b4f-6cc9-436b-aba7-fe93d2a1ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codadad and his brothers requested the princess to tell them her story and after thanking them for their repeated protestations of readiness to serve her she could not refuse to satisfy their curiosity and began the recital of her adventures in the following manner \n"
     ]
    }
   ],
   "source": [
    "string_sent = ''\n",
    "for word in full_sentence:\n",
    "    if len(word)>0:\n",
    "        string_sent += word + \" \"\n",
    "print(string_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28ab2315-aaba-47ec-860c-4e9be6e85c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folklore legends myths and fairy tales have followed childhood through the ages for every healthy youngster has a wholesome and instinctive love for stories fantastic marvelous and manifestly unreal \n"
     ]
    }
   ],
   "source": [
    "string_sent = ''\n",
    "for word in full_sentence:\n",
    "    if len(word)>0:\n",
    "        string_sent += word + \" \"\n",
    "print(string_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38b19a58-5d5f-43a2-9d5c-1f3ded4b81e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is it from the forgetfulness or negligence of the workmen or want of time that they have not put a morsel of anything into my mouth these three days \n"
     ]
    }
   ],
   "source": [
    "string_sent = ''\n",
    "for word in full_sentence:\n",
    "    if len(word)>0:\n",
    "        string_sent += word + \" \"\n",
    "print(string_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "977c2eb2-3a22-48af-b59a-ac4667d145d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "they walked over a pavement of the same green marble and where the blocks were joined together were rows of emeralds set closely and glittering in the brightness of the sun \n"
     ]
    }
   ],
   "source": [
    "string_sent = ''\n",
    "for word in full_sentence:\n",
    "    if len(word)>0:\n",
    "        string_sent += word + \" \"\n",
    "print(string_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd244a2e-217a-424e-9046-48259b4cbd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
