{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f66bb3-d453-4dc8-848c-55fa49de3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebooklib import epub\n",
    "import os\n",
    "import ebooklib\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d66c95e-76ef-4916-bd71-102cdfbbd597",
   "metadata": {},
   "source": [
    "<h1> Ingest all of the books and extract the text from them </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37bf4e0-1954-45e3-ab3c-bd2fc6eea254",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_list = [\"<class 'ebooklib.epub.EpubImage'>\",\"<class 'ebooklib.epub.EpubItem'>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f10c7a-f6e6-4faa-8992-3566ed2bdb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books = []\n",
    "for filename in os.listdir('books/'):\n",
    "    if filename.endswith('.epub'):\n",
    "        book = epub.read_epub('books/' + filename)\n",
    "        book_text = ''\n",
    "        for doc in book.get_items():\n",
    "            if not str(type(doc)) in ignore_list:\n",
    "                doc_content = doc.content.decode()\n",
    "                book_text += doc_content\n",
    "        book_text = book_text.split('\\n')\n",
    "        for line in book_text:\n",
    "            if line.startswith('<p>'):\n",
    "                line = line.replace('<p>','').replace('</p>','')\n",
    "                line=line.replace(';','.').replace('!','.').replace('?','.')\n",
    "                line = line.split(\".\")\n",
    "                for sent in line:\n",
    "                    if sent.startswith(\" \"):\n",
    "                        sent = sent[1:]\n",
    "                    if sent.endswith(\" \"):\n",
    "                        sent = sent[:-1]\n",
    "                    if '<a' in sent:\n",
    "                        sent_start = sent.split('<a')[0]\n",
    "                        try:\n",
    "                            sent_end = sent.split('</a>')[1]\n",
    "                        except:\n",
    "                            sent_end = ''\n",
    "                        sent = sent_start + sent_end\n",
    "                    sent = sent.replace('<i>','').replace('</i>','').replace('<b>','').replace('</b>','')\n",
    "                    if len(sent) > 1 and sent != '<br/>':\n",
    "                        all_books.append(sent.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c225a-43bb-4814-8d49-bcef37093be1",
   "metadata": {},
   "source": [
    "<h1> Create corpus and reverse corpus </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede64be2-f0d6-42ec-8ad3-221787428a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}\n",
    "reverse_corpus = {0:''}\n",
    "counter=1\n",
    "punct = ['!','\"','#','$','%','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[','\\\\',']','^','_','`','{','Â¦','}','~']\n",
    "for sent in all_books:\n",
    "    for punc in punct:\n",
    "        sent=sent.replace(punc,' ')\n",
    "    sent=sent.split(' ')\n",
    "    for word in sent:\n",
    "        if not word in corpus and word != ' ' and len(word) > 0:\n",
    "            corpus[word]=counter\n",
    "            reverse_corpus[counter]=word\n",
    "            counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec482b6-d652-47f5-84c1-dd33e49648b0",
   "metadata": {},
   "source": [
    "<h1> Convert sentences to arrays using the corpus </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc82912-20e5-4181-bf11-fc192e9a3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_books_indexed = []\n",
    "for sent in all_books:\n",
    "    temp_list = []\n",
    "    for punc in punct:\n",
    "        sent=sent.replace(punc,' ')\n",
    "    sent=sent.split(' ')\n",
    "    for word in sent:\n",
    "        try:\n",
    "            temp_list.append(corpus[word])\n",
    "        except:\n",
    "            continue\n",
    "    all_books_indexed.append(temp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3ae77-9353-43b2-b92f-a5c46d22ba07",
   "metadata": {},
   "source": [
    "<h1> Find the max sentence length </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d142d1f-192a-44f6-9965-69904bd3bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "for i in range(len(all_books_indexed)):\n",
    "    if len(all_books_indexed[i]) > max_length:\n",
    "        max_length = len(all_books_indexed[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a1d34-9de6-4ec9-ade1-e3caafcac41d",
   "metadata": {},
   "source": [
    "<h1> Pad sentences to all be the same length </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd66bab-9c0d-429f-8411-9f487667b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_books_indexed)):\n",
    "    while len(all_books_indexed[i]) < max_length:\n",
    "        all_books_indexed[i].insert(0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ffd635-1f21-4dc3-8221-a10cee36a35b",
   "metadata": {},
   "source": [
    "<h1> Create a dictionary for each position in the array containing each word that appears. </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bbdaa5b-1329-45cd-b571-0add0f47e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict = {}\n",
    "for sent in all_books_indexed:\n",
    "    for i in range(max_length):\n",
    "        if not i in position_dict:\n",
    "            position_dict[i] = [{}]\n",
    "        if not sent[i] in position_dict[i][0]:\n",
    "            position_dict[i][0][sent[i]]=1\n",
    "        else:\n",
    "            position_dict[i][0][sent[i]]+=1\n",
    "\n",
    "for position in position_dict:\n",
    "    total = 0\n",
    "    temp_list = []\n",
    "    temp_word_list = []\n",
    "    for word in position_dict[position][0]:\n",
    "        count = position_dict[position][0][word]\n",
    "        temp_list.append(count)\n",
    "        temp_word_list.append(word)\n",
    "        total += count\n",
    "    for i in range(len(temp_list)):\n",
    "        temp_list[i] = temp_list[i]/total\n",
    "        if i >= 1:\n",
    "            temp_list[i] += temp_list[i-1]\n",
    "    position_dict[position].append(temp_list)\n",
    "    position_dict[position].append(temp_word_list)\n",
    "total_sents = total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba63f7-1f42-4103-8975-c98670adce8f",
   "metadata": {},
   "source": [
    "<h1> Create a dictionaries with look-backs. </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7a792-4153-4052-b56f-cba51b34cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict_2 = {}\n",
    "for sent in all_books_indexed:\n",
    "    for i in range(max_length):\n",
    "        if not i in position_dict_2:\n",
    "            position_dict_2[i] = [{}]\n",
    "        if i > 0:\n",
    "            if not (sent[i-1],sent[i]) in position_dict_2[i][0]:\n",
    "                position_dict_2[i][0][(sent[i-1],sent[i])]=1\n",
    "            else:\n",
    "                position_dict_2[i][0][(sent[i-1],sent[i])]+=1\n",
    "        else:\n",
    "            if not (0,0) in position_dict_2[i][0]:\n",
    "                position_dict_2[i][0][(0,0)]=1\n",
    "            else:\n",
    "                position_dict_2[i][0][(0,0)]+=1\n",
    "\n",
    "for position in position_dict_2:\n",
    "    total = 0\n",
    "    temp_list = []\n",
    "    temp_word_list = []\n",
    "    for word in position_dict_2[position][0]:\n",
    "        count = position_dict_2[position][0][word]\n",
    "        temp_list.append(count)\n",
    "        temp_word_list.append(word)\n",
    "        total += count\n",
    "    for i in range(len(temp_list)):\n",
    "        temp_list[i] = temp_list[i]/total\n",
    "        if i >= 1:\n",
    "            temp_list[i] += temp_list[i-1]\n",
    "    position_dict_2[position].append(temp_list)\n",
    "    position_dict_2[position].append(temp_word_list)\n",
    "total_sents = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8db7cbd-60e1-40c4-8a59-ea8cdc037507",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict_3 = {}\n",
    "for sent in all_books_indexed:\n",
    "    for i in range(max_length):\n",
    "        if not i in position_dict_3:\n",
    "            position_dict_3[i] = [{}]\n",
    "        if i > 1:\n",
    "            if not (sent[i-2],sent[i-1],sent[i]) in position_dict_3[i][0]:\n",
    "                position_dict_3[i][0][(sent[i-2],sent[i-1],sent[i])]=1\n",
    "            else:\n",
    "                position_dict_3[i][0][(sent[i-2],sent[i-1],sent[i])]+=1\n",
    "        else:\n",
    "            if not (0,0,0) in position_dict_3[i][0]:\n",
    "                position_dict_3[i][0][(0,0,0)]=1\n",
    "            else:\n",
    "                position_dict_3[i][0][(0,0,0)]+=1\n",
    "\n",
    "for position in position_dict_3:\n",
    "    total = 0\n",
    "    temp_list = []\n",
    "    temp_word_list = []\n",
    "    for word in position_dict_3[position][0]:\n",
    "        count = position_dict_3[position][0][word]\n",
    "        temp_list.append(count)\n",
    "        temp_word_list.append(word)\n",
    "        total += count\n",
    "    for i in range(len(temp_list)):\n",
    "        temp_list[i] = temp_list[i]/total\n",
    "        if i >= 1:\n",
    "            temp_list[i] += temp_list[i-1]\n",
    "    position_dict_3[position].append(temp_list)\n",
    "    position_dict_3[position].append(temp_word_list)\n",
    "total_sents = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ee310dc-031d-45ac-8dc7-720059739185",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_dict_4 = {}\n",
    "for sent in all_books_indexed:\n",
    "    for i in range(max_length):\n",
    "        if not i in position_dict_4:\n",
    "            position_dict_4[i] = [{}]\n",
    "        if i > 2:\n",
    "            if not (sent[i-3],sent[i-2],sent[i-1],sent[i]) in position_dict_4[i][0]:\n",
    "                position_dict_4[i][0][(sent[i-3],sent[i-2],sent[i-1],sent[i])]=1\n",
    "            else:\n",
    "                position_dict_4[i][0][(sent[i-3],sent[i-2],sent[i-1],sent[i])]+=1\n",
    "        else:\n",
    "            if not (0,0,0,0) in position_dict_4[i][0]:\n",
    "                position_dict_4[i][0][(0,0,0,0)]=1\n",
    "            else:\n",
    "                position_dict_4[i][0][(0,0,0,0)]+=1\n",
    "\n",
    "for position in position_dict_4:\n",
    "    total = 0\n",
    "    temp_list = []\n",
    "    temp_word_list = []\n",
    "    for word in position_dict_4[position][0]:\n",
    "        count = position_dict_4[position][0][word]\n",
    "        temp_list.append(count)\n",
    "        temp_word_list.append(word)\n",
    "        total += count\n",
    "    for i in range(len(temp_list)):\n",
    "        temp_list[i] = temp_list[i]/total\n",
    "        if i >= 1:\n",
    "            temp_list[i] += temp_list[i-1]\n",
    "    position_dict_4[position].append(temp_list)\n",
    "    position_dict_4[position].append(temp_word_list)\n",
    "total_sents = total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494f399-93f3-4152-bcc1-33befd8622e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>Define the function to generate the text</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f4124218-f712-4c00-9ea3-1e74b838a821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_sent():\n",
    "    full_sent = ''\n",
    "    full_sent_len = 0\n",
    "    random_base = 0\n",
    "    while full_sent_len < 1:\n",
    "        full_sentence = []\n",
    "        for i in range(max_length):\n",
    "            rand_num = random.uniform(random_base,1)\n",
    "            if i == 0:\n",
    "                position_weights = position_dict[i][1]\n",
    "\n",
    "                indexer = 0\n",
    "                for x in range(len(position_weights)):\n",
    "                    if rand_num > position_weights[x]:\n",
    "                        indexer = x\n",
    "\n",
    "                full_sentence.append(reverse_corpus[position_dict[i][2][indexer]])\n",
    "                full_sent+=reverse_corpus[position_dict[i][2][indexer]]\n",
    "            # else:\n",
    "            elif i ==1:\n",
    "                temp_list = []\n",
    "                word_list = []\n",
    "                total_count = 0\n",
    "                position_words = position_dict_2[i][2]\n",
    "                for pos in position_words:\n",
    "                    pos0 = reverse_corpus[int(pos[0])]\n",
    "                    if full_sentence[i-1] == pos0 :\n",
    "                        total_count += position_dict_2[i][0][pos]\n",
    "                        word_list.append(pos)\n",
    "                for pos in word_list:\n",
    "                    temp_val= position_dict_2[i][0][pos]\n",
    "                    temp_list.append(temp_val/total_count)\n",
    "                for val in range(len(temp_list)):\n",
    "                    if val > 0:\n",
    "                        temp_list[val] += temp_list[val-1]\n",
    "                indexer = 0\n",
    "                for x in range(len(temp_list)):\n",
    "                    if rand_num > temp_list[x]:\n",
    "                            indexer = x\n",
    "                full_sentence.append(reverse_corpus[word_list[indexer][1]])\n",
    "                full_sent+=reverse_corpus[word_list[indexer][1]]\n",
    "            elif i ==2:\n",
    "                temp_list = []\n",
    "                word_list = []\n",
    "                total_count = 0\n",
    "                position_words = position_dict_3[i][2]\n",
    "                for pos in position_words:\n",
    "                    pos0 = reverse_corpus[int(pos[0])]\n",
    "                    pos1 = reverse_corpus[int(pos[1])]\n",
    "                    if full_sentence[i-1] == pos1 and full_sentence[i-2] == pos0:\n",
    "                        total_count += position_dict_3[i][0][pos]\n",
    "                        word_list.append(pos)\n",
    "                for pos in word_list:\n",
    "                    temp_val= position_dict_3[i][0][pos]\n",
    "                    temp_list.append(temp_val/total_count)\n",
    "                for val in range(len(temp_list)):\n",
    "                    if val > 0:\n",
    "                        temp_list[val] += temp_list[val-1]\n",
    "                indexer = 0\n",
    "                for x in range(len(temp_list)):\n",
    "                    if rand_num > temp_list[x]:\n",
    "                            indexer = x\n",
    "                full_sentence.append(reverse_corpus[word_list[indexer][2]])\n",
    "                full_sent+=reverse_corpus[word_list[indexer][2]]\n",
    "            else:\n",
    "                temp_list = []\n",
    "                word_list = []\n",
    "                total_count = 0\n",
    "                position_words = position_dict_4[i][2]\n",
    "                for pos in position_words:\n",
    "                    pos0 = reverse_corpus[int(pos[0])]\n",
    "                    pos1 = reverse_corpus[int(pos[1])]\n",
    "                    pos2 = reverse_corpus[int(pos[2])]\n",
    "                    if full_sentence[i-1] == pos2 and full_sentence[i-2] == pos1 and full_sentence[i-3] == pos0:\n",
    "                        total_count += position_dict_4[i][0][pos]\n",
    "                        word_list.append(pos)\n",
    "                for pos in word_list:\n",
    "                    temp_val= position_dict_4[i][0][pos]\n",
    "                    temp_list.append(temp_val/total_count)\n",
    "                for val in range(len(temp_list)):\n",
    "                    if val > 0:\n",
    "                        temp_list[val] += temp_list[val-1]\n",
    "                indexer = 0\n",
    "                for x in range(len(temp_list)):\n",
    "                    if rand_num > temp_list[x]:\n",
    "                            indexer = x\n",
    "                full_sentence.append(reverse_corpus[word_list[indexer][3]])\n",
    "                full_sent+=reverse_corpus[word_list[indexer][3]]\n",
    "\n",
    "        full_sent_len = len(full_sent)\n",
    "        random_base += 0.001\n",
    "    string_sent = ''\n",
    "    for word in full_sentence:\n",
    "        if len(word)>0:\n",
    "            string_sent += word + \" \"\n",
    "    print(string_sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b06c6d-00e2-4f8d-af8d-00b3d0df4f79",
   "metadata": {},
   "source": [
    "<h1>Test it out</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd244a2e-217a-424e-9046-48259b4cbd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afterward it was noticed that the wizard always performed his famous trick with eight piglets but it seemed to please the people just as well as if they had been from infancy accustomed \n"
     ]
    }
   ],
   "source": [
    "make_sent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1425df2-d5a4-4d41-92b5-ed2d1b6f6a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folklore legends myths and fairy tales have followed childhood through the ages for every healthy youngster has a wholesome and instinctive love for stories fantastic marvelous and manifestly unreal \n"
     ]
    }
   ],
   "source": [
    "make_sent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ddc61-44f7-4007-a1ce-138ee1440cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
